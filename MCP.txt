 1. ツール定義の標準化 (Tools)

  現状、LLMが実行できるアクション（タスク作成、完了など）は、llm_client.py
  内のシステムプロンプトに自然言語のテキストとしてハードコードされています。

   * 現状 (Before):
       * プロンプト内で「{"type":"create_custom_task", ...} というJSONを返して」と指示している。
       * LLMが返すテキストから _extract_json_object
         関数を使って無理やりJSONを抽出している（エラーが起きやすく脆い）。
       * 新しい機能を追加するたびに、プロンプトが長くなり、LLMが混乱しやすくなる。

   * MCP導入案 (After):
       * create_custom_task や toggle_step などを、MCPツールとして定義し、JSON
         Schemaで引数を厳密に規定する。
       * メリット:
           * LLMのネイティブな Function Calling (Tool Use)
             機能を利用できるようになり、JSONパースの失敗がほぼゼロになる。
           * _extract_json_object のような不安定なパース処理を削除できる。
           * ツールの定義がコード（Python関数）と直結するため、保守性が向上する。

  2. コンテキスト提供の構造化 (Resources)

  現在、スケジュールの内容やログデータは、app.py の _build_scheduler_context
  関数によって巨大なテキストブロックに変換され、プロンプトに埋め込まれています。

   * 現状 (Before):
       * DBから取得したデータを today_date: ... routines: ... のような独自のテキスト形式に整形している。
       * 常に全ての情報（過去のログ含む）をプロンプトに含めるため、トークン消費量が多く、LLMの注目箇所が分散しやすい。

   * MCP導入案 (After):
       * 今日の日程やログを MCPリソース (scheduler://schedule/today, scheduler://logs/recent など)
         として公開する。
       * メリット:
           * LLMが必要な情報だけを「リソース」として読み込めるようになる。
           * データの形式が明確になり、LLMが内容を誤解しにくくなる。
           * 将来的にカレンダーアプリなど外部のMCPサーバーと連携する際、同じインターフェースで扱える。

  3. ロジックの分離と再利用性

  現在は app.py の _apply_actions
  内に、アクションごとの処理ロジックが分岐（if/elif）として記述されています。

   * MCP導入案:
       * これらをMCPサーバー側の「ツール実行ハンドラ」として独立させる。
   * メリット:
       * Flaskアプリケーション（Web UI）と、LLMのエージェント機能（ロジック）を疎結合にできる。
       * 例えば、このスケジューラー機能を、他のAIエージェント（CLIツールや他のWebアプリ）から「MCPクライアン
         ト」を通じて利用可能になる。

  まとめ

  結論:
  特に 「1. ツール定義の標準化」 は直ちに導入する価値があります。現在の llm_client.py
  にある不安定なJSON抽出ロジックを廃止し、モダンなTool
  Callingに移行できるため、エージェントの動作安定性が劇的に向上します。